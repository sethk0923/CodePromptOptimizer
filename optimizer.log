DEBUG:root:Optimize button clicked
DEBUG:root:Processing prompt: fix this
ERROR:root:Error generating steps: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:26:00,759 - INFO - Successfully downloaded NLTK data
2025-02-18 22:26:06,382 - DEBUG - Optimize button clicked
2025-02-18 22:26:06,382 - DEBUG - Processing prompt: fix this
2025-02-18 22:26:06,385 - ERROR - Error generating steps: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:27:01,242 - INFO - Found NLTK resource: punkt
2025-02-18 22:27:01,244 - INFO - Downloading missing NLTK resources: ['stopwords']
2025-02-18 22:27:01,337 - INFO - Successfully downloaded stopwords
2025-02-18 22:27:06,891 - DEBUG - Optimize button clicked
2025-02-18 22:27:06,892 - DEBUG - Processing prompt: fix this file
2025-02-18 22:27:06,895 - ERROR - NLTK sentence tokenization failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:27:06,898 - ERROR - NLTK word tokenization failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:27:07,065 - DEBUG - Steps generated successfully
2025-02-18 22:27:48,951 - DEBUG - Optimize button clicked
2025-02-18 22:27:48,952 - DEBUG - Processing prompt: review this file and fix why the next step navigaiton button won't go to step 6
2025-02-18 22:27:48,952 - DEBUG - File path: C:/Users/sethk/OneDrive/Documents/xaix/Python_Sentinel_Risk/app/templates/rcsa/step5_review.html
2025-02-18 22:27:48,961 - ERROR - NLTK sentence tokenization failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:27:48,964 - ERROR - NLTK word tokenization failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - 'C:\\Users\\sethk/nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\share\\nltk_data'
    - 'C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\lib\\nltk_data'
    - 'C:\\Users\\sethk\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
**********************************************************************

2025-02-18 22:27:48,978 - DEBUG - Steps generated successfully
2025-02-19 01:27:46,567 - INFO - Successfully initialized tiktoken with gpt-3.5-turbo encoding
2025-02-19 01:27:57,599 - DEBUG - Optimize button clicked
2025-02-19 01:27:57,600 - DEBUG - Processing prompt: create a story about a girl that moves to mars.
2025-02-19 01:27:57,604 - DEBUG - Steps generated successfully
2025-02-19 01:28:20,282 - DEBUG - Optimize button clicked
2025-02-19 01:28:20,283 - DEBUG - Processing prompt: fix the handlers for step 5
2025-02-19 01:28:20,283 - DEBUG - Processing file: C:/Users/sethk/OneDrive/Documents/xaix/Python_Sentinel_Risk/app/templates/rcsa/step5_review.html
2025-02-19 01:28:20,295 - DEBUG - Steps generated successfully
2025-02-19 01:30:14,219 - INFO - Successfully initialized tiktoken with gpt-3.5-turbo encoding
2025-02-19 01:30:52,246 - INFO - Successfully initialized tiktoken with gpt-3.5-turbo encoding
2025-02-19 01:31:15,448 - DEBUG - Optimize button clicked
2025-02-19 01:31:15,449 - DEBUG - Processing prompt: Review this calculator code and suggest improvements
2025-02-19 01:31:15,449 - DEBUG - Processing file: C:/Users/sethk/OneDrive/Documents/tokenizerv2/test_code.py
2025-02-19 01:31:15,452 - DEBUG - Steps generated successfully
2025-02-19 01:31:57,479 - INFO - Successfully initialized tiktoken with gpt-3.5-turbo encoding
2025-02-19 01:32:06,844 - DEBUG - Optimize button clicked
2025-02-19 01:32:06,844 - DEBUG - Processing prompt: Review this calculator code and suggest improvements
2025-02-19 01:32:06,844 - DEBUG - Processing file: C:/Users/sethk/OneDrive/Documents/tokenizerv2/test_code.py
2025-02-19 01:32:06,846 - DEBUG - Extracted 1 code blocks from C:/Users/sethk/OneDrive/Documents/tokenizerv2/test_code.py
2025-02-19 01:32:06,851 - DEBUG - Steps generated successfully
2025-02-19 01:33:46,427 - INFO - Successfully initialized tiktoken with gpt-3.5-turbo encoding
2025-02-19 01:34:22,461 - DEBUG - Optimize button clicked
2025-02-19 01:34:22,461 - DEBUG - Processing prompt: Review this calculator code and suggest improvements
2025-02-19 01:34:22,462 - DEBUG - Processing file: C:/Users/sethk/OneDrive/Documents/tokenizerv2/styles.css
2025-02-19 01:34:22,463 - DEBUG - Extracted 8 code blocks from C:/Users/sethk/OneDrive/Documents/tokenizerv2/styles.css (.css file)
2025-02-19 01:34:22,467 - DEBUG - Steps generated successfully
2025-02-19 01:34:53,098 - DEBUG - Optimize button clicked
2025-02-19 01:34:53,098 - DEBUG - Processing prompt: Review this calculator code and suggest improvements
2025-02-19 01:34:53,099 - DEBUG - Processing file: C:/Users/sethk/OneDrive/Documents/tokenizerv2/test.html
2025-02-19 01:34:53,100 - DEBUG - Extracted 7 code blocks from C:/Users/sethk/OneDrive/Documents/tokenizerv2/test.html (.html file)
2025-02-19 01:34:53,101 - DEBUG - Steps generated successfully
2025-02-19 21:29:50,802 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-19 21:29:50,925 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-19 21:29:50,930 - DEBUG - Attempting to acquire lock 2520836797200 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock
2025-02-19 21:29:50,931 - DEBUG - Lock 2520836797200 acquired on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock
2025-02-19 21:29:51,047 - DEBUG - https://huggingface.co:443 "GET /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 26
2025-02-19 21:29:51,071 - DEBUG - Attempting to release lock 2520836797200 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock
2025-02-19 21:29:51,071 - DEBUG - Lock 2520836797200 released on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\be4d21d94f3b4687e5a54d84bf6ab46ed0f8defd.lock
2025-02-19 21:29:51,128 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/vocab.json HTTP/1.1" 200 0
2025-02-19 21:29:51,131 - DEBUG - Attempting to acquire lock 2520836837280 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock
2025-02-19 21:29:51,131 - DEBUG - Lock 2520836837280 acquired on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock
2025-02-19 21:29:51,192 - DEBUG - https://huggingface.co:443 "GET /gpt2/resolve/main/vocab.json HTTP/1.1" 200 1042301
2025-02-19 21:29:51,290 - DEBUG - Attempting to release lock 2520836837280 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock
2025-02-19 21:29:51,291 - DEBUG - Lock 2520836837280 released on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\1f1d9aaca301414e7f6c9396df506798ff4eb9a6.lock
2025-02-19 21:29:51,347 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/merges.txt HTTP/1.1" 200 0
2025-02-19 21:29:51,350 - DEBUG - Attempting to acquire lock 2520853758256 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock
2025-02-19 21:29:51,350 - DEBUG - Lock 2520853758256 acquired on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock
2025-02-19 21:29:51,414 - DEBUG - https://huggingface.co:443 "GET /gpt2/resolve/main/merges.txt HTTP/1.1" 200 456318
2025-02-19 21:29:51,454 - DEBUG - Attempting to release lock 2520853758256 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock
2025-02-19 21:29:51,455 - DEBUG - Lock 2520853758256 released on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\226b0752cac7789c48f0cb3ec53eda48b7be36cc.lock
2025-02-19 21:29:51,510 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/added_tokens.json HTTP/1.1" 404 0
2025-02-19 21:29:51,576 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/special_tokens_map.json HTTP/1.1" 404 0
2025-02-19 21:29:51,634 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer.json HTTP/1.1" 200 0
2025-02-19 21:29:51,637 - DEBUG - Attempting to acquire lock 2520836837280 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\4b988bccc9dc5adacd403c00b4704976196548f8.lock
2025-02-19 21:29:51,638 - DEBUG - Lock 2520836837280 acquired on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\4b988bccc9dc5adacd403c00b4704976196548f8.lock
2025-02-19 21:29:51,706 - DEBUG - https://huggingface.co:443 "GET /gpt2/resolve/main/tokenizer.json HTTP/1.1" 200 1355256
2025-02-19 21:29:51,775 - DEBUG - Attempting to release lock 2520836837280 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\4b988bccc9dc5adacd403c00b4704976196548f8.lock
2025-02-19 21:29:51,776 - DEBUG - Lock 2520836837280 released on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\4b988bccc9dc5adacd403c00b4704976196548f8.lock
2025-02-19 21:29:51,839 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/chat_template.jinja HTTP/1.1" 404 0
2025-02-19 21:29:51,917 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/config.json HTTP/1.1" 200 0
2025-02-19 21:29:51,919 - DEBUG - Attempting to acquire lock 2520854527952 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\10c66461e4c109db5a2196bff4bb59be30396ed8.lock
2025-02-19 21:29:51,920 - DEBUG - Lock 2520854527952 acquired on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\10c66461e4c109db5a2196bff4bb59be30396ed8.lock
2025-02-19 21:29:51,989 - DEBUG - https://huggingface.co:443 "GET /gpt2/resolve/main/config.json HTTP/1.1" 200 665
2025-02-19 21:29:52,000 - DEBUG - Attempting to release lock 2520854527952 on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\10c66461e4c109db5a2196bff4bb59be30396ed8.lock
2025-02-19 21:29:52,001 - DEBUG - Lock 2520854527952 released on C:\Users\sethk\.cache\huggingface\hub\.locks\models--gpt2\10c66461e4c109db5a2196bff4bb59be30396ed8.lock
2025-02-19 21:29:52,106 - INFO - Successfully initialized GPT-2 tokenizer
2025-02-19 21:29:56,124 - DEBUG - Optimize button clicked
2025-02-19 21:29:56,124 - DEBUG - Processing prompt: dssadsaf
2025-02-19 21:29:56,195 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-19 21:29:56,264 - INFO - Successfully initialized GPT-2 tokenizer
2025-02-19 21:29:56,324 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-19 21:29:56,389 - INFO - Successfully initialized GPT-2 tokenizer
2025-02-19 21:29:56,455 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-19 21:29:56,521 - INFO - Successfully initialized GPT-2 tokenizer
2025-02-19 21:29:56,526 - DEBUG - Steps generated successfully
2025-02-19 21:52:14,776 - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2025-02-19 21:52:14,919 - DEBUG - https://huggingface.co:443 "HEAD /gpt2/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-02-19 21:52:15,030 - INFO - Successfully initialized GPT-2 tokenizer
